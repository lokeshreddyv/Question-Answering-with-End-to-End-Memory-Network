{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling, read-binary\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the train data contains 10,000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Daniel',\n",
       "  'went',\n",
       "  'to',\n",
       "  'the',\n",
       "  'office',\n",
       "  '.'],\n",
       " ['Is', 'Mary', 'in', 'the', 'bathroom', '?'],\n",
       " 'yes')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story:\n",
      "Daniel grabbed the apple there.\n",
      "Daniel went to the bedroom.\n",
      "John moved to the garden.\n",
      "Sandra journeyed to the office.\n",
      "Daniel put down the apple.\n",
      "Mary went to the bedroom.\n",
      "Mary grabbed the apple there.\n",
      "Sandra went back to the garden.\n",
      "Mary went to the kitchen.\n",
      "Daniel went to the office.\n",
      "\n",
      "Question: Is Mary in the garden?\n",
      "\n",
      "Answer: no\n"
     ]
    }
   ],
   "source": [
    "text=''\n",
    "print('Story:')\n",
    "for sent in train_data[99]:\n",
    "    if sent!='yes' and sent!='no':\n",
    "        for word in sent:\n",
    "            if (word!='.'):\n",
    "                if (word!='?'):\n",
    "                    text+= word + ' '\n",
    "                else:\n",
    "                    print()\n",
    "                    print('Question:', text[:-1]+word)\n",
    "                    print()\n",
    "            else:\n",
    "                print(text[:-1]+word)\n",
    "                text=''\n",
    "    else:\n",
    "        print('Answer:', sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- list of tuples\n",
    "    - tuple contains: story x, question q and answer a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'journeyed',\n",
       " 'moved',\n",
       " 'the',\n",
       " 'to'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_data[0][0]) # story component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- adding the answer possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 # we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])   # provide empty list for filter out\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropped': 1,\n",
       " 'journeyed': 2,\n",
       " 'no': 3,\n",
       " 'sandra': 4,\n",
       " 'mary': 5,\n",
       " 'got': 6,\n",
       " 'apple': 7,\n",
       " 'office': 8,\n",
       " 'travelled': 9,\n",
       " 'discarded': 10,\n",
       " 'bathroom': 11,\n",
       " 'the': 12,\n",
       " 'took': 13,\n",
       " 'grabbed': 14,\n",
       " 'kitchen': 15,\n",
       " '?': 16,\n",
       " 'down': 17,\n",
       " '.': 18,\n",
       " 'to': 19,\n",
       " 'hallway': 20,\n",
       " 'is': 21,\n",
       " 'went': 22,\n",
       " 'back': 23,\n",
       " 'yes': 24,\n",
       " 'john': 25,\n",
       " 'up': 26,\n",
       " 'football': 27,\n",
       " 'in': 28,\n",
       " 'put': 29,\n",
       " 'milk': 30,\n",
       " 'daniel': 31,\n",
       " 'left': 32,\n",
       " 'picked': 33,\n",
       " 'there': 34,\n",
       " 'garden': 35,\n",
       " 'bedroom': 36,\n",
       " 'moved': 37}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(vocab_size)  # this includes +1 for padding\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 12, 36, 18],\n",
       "       [ 0,  0,  0, ..., 12, 35, 18],\n",
       "       [ 0,  0,  0, ..., 12, 35, 18],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 12,  7, 18],\n",
       "       [ 0,  0,  0, ..., 12, 35, 18],\n",
       "       [ 0,  0,  0, ...,  7, 34, 18]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding mode 'pre'\n",
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 25, 28, 12, 15, 16],\n",
       "       [21, 25, 28, 12, 15, 16],\n",
       "       [21, 25, 28, 12, 35, 16],\n",
       "       ...,\n",
       "       [21,  5, 28, 12, 36, 16],\n",
       "       [21,  4, 28, 12, 35, 16],\n",
       "       [21,  5, 28, 12, 35, 16]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot vectors of size V vocabulary for Yes / No\n",
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0., 503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 497.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equal proportion of Yes / No answers\n",
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from tensorflow.keras.layers import add, dot, concatenate\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "\n",
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim= embedding_dim))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embedding_dim,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices) to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "# (samples, query_maxlen, story_maxlen + embedding_dim)\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 6, 284) dtype=float32 (created by layer 'concatenate_5')>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # shape (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 156)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_16 (Sequential)      (None, None, 128)    4864        input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential_18 (Sequential)      (None, 6, 128)       4864        input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_5 (Dot)                     (None, 156, 6)       0           sequential_16[0][0]              \n",
      "                                                                 sequential_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 156, 6)       0           dot_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_17 (Sequential)      (None, None, 6)      228         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 156, 6)       0           activation_16[0][0]              \n",
      "                                                                 sequential_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "permute_5 (Permute)             (None, 6, 156)       0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 6, 284)       0           permute_5[0][0]                  \n",
      "                                                                 sequential_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 32)           40576       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 32)           0           lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 38)           1254        dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 38)           0           dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 51,786\n",
      "Trainable params: 51,786\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "initial_learning_rate = 0.01\n",
    "epochs = 120\n",
    "decay = initial_learning_rate / epochs\n",
    "\n",
    "def lr_step_decay(epoch, lr):\n",
    "    drop_rate = 0.5\n",
    "    epochs_drop = 20\n",
    "    return initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))\n",
    "\n",
    "learning_rate = LearningRateScheduler(lr_step_decay, verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.66, patience=5, min_lr=0.0001, verbose=1)  # factor by which the learning rate will be reduced. new_lr = lr * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "40/40 [==============================] - 5s 79ms/step - loss: 1.2886 - accuracy: 0.4478 - val_loss: 0.6969 - val_accuracy: 0.5030\n",
      "Epoch 2/120\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.7145 - accuracy: 0.4878 - val_loss: 0.8687 - val_accuracy: 0.4970\n",
      "Epoch 3/120\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.7206 - accuracy: 0.4935 - val_loss: 0.6938 - val_accuracy: 0.5030\n",
      "Epoch 4/120\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.7014 - accuracy: 0.5080 - val_loss: 0.7082 - val_accuracy: 0.4970\n",
      "Epoch 5/120\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.6972 - accuracy: 0.5120 - val_loss: 0.7052 - val_accuracy: 0.5030\n",
      "Epoch 6/120\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.6947 - accuracy: 0.5189 - val_loss: 0.6011 - val_accuracy: 0.6650\n",
      "Epoch 7/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.5402 - accuracy: 0.7323 - val_loss: 0.4762 - val_accuracy: 0.7680\n",
      "Epoch 8/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.4380 - accuracy: 0.8155 - val_loss: 0.4169 - val_accuracy: 0.8070\n",
      "Epoch 9/120\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.3895 - accuracy: 0.8372 - val_loss: 0.4177 - val_accuracy: 0.8340\n",
      "Epoch 10/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.3531 - accuracy: 0.8486 - val_loss: 0.6276 - val_accuracy: 0.7250\n",
      "Epoch 11/120\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.3580 - accuracy: 0.8414 - val_loss: 0.4226 - val_accuracy: 0.8000\n",
      "Epoch 12/120\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.3441 - accuracy: 0.8504 - val_loss: 0.3879 - val_accuracy: 0.8290\n",
      "Epoch 13/120\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.3284 - accuracy: 0.8541 - val_loss: 0.3610 - val_accuracy: 0.8330\n",
      "Epoch 14/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.3006 - accuracy: 0.8661 - val_loss: 0.3927 - val_accuracy: 0.8270\n",
      "Epoch 15/120\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.2961 - accuracy: 0.8680 - val_loss: 0.3516 - val_accuracy: 0.8280\n",
      "Epoch 16/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.3009 - accuracy: 0.8647 - val_loss: 0.3754 - val_accuracy: 0.8300\n",
      "Epoch 17/120\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.3036 - accuracy: 0.8648 - val_loss: 0.3478 - val_accuracy: 0.8340\n",
      "Epoch 18/120\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.2855 - accuracy: 0.8715 - val_loss: 0.3810 - val_accuracy: 0.8310\n",
      "Epoch 19/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.2990 - accuracy: 0.8587 - val_loss: 0.3433 - val_accuracy: 0.8350\n",
      "Epoch 20/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.2866 - accuracy: 0.8689 - val_loss: 0.3407 - val_accuracy: 0.8410\n",
      "Epoch 21/120\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2827 - accuracy: 0.87 - 3s 63ms/step - loss: 0.2828 - accuracy: 0.8736 - val_loss: 0.3303 - val_accuracy: 0.8430\n",
      "Epoch 22/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.2673 - accuracy: 0.8823 - val_loss: 0.3244 - val_accuracy: 0.8490\n",
      "Epoch 23/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.2620 - accuracy: 0.8834 - val_loss: 0.4104 - val_accuracy: 0.8300\n",
      "Epoch 24/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.2548 - accuracy: 0.8867 - val_loss: 0.2909 - val_accuracy: 0.8830\n",
      "Epoch 25/120\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.2197 - accuracy: 0.9033 - val_loss: 0.2397 - val_accuracy: 0.8930\n",
      "Epoch 26/120\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1908 - accuracy: 0.9142 - val_loss: 0.2543 - val_accuracy: 0.8910\n",
      "Epoch 27/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1819 - accuracy: 0.9191 - val_loss: 0.2368 - val_accuracy: 0.8820\n",
      "Epoch 28/120\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1660 - accuracy: 0.9309 - val_loss: 0.3271 - val_accuracy: 0.8690\n",
      "Epoch 29/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1972 - accuracy: 0.9229 - val_loss: 0.2113 - val_accuracy: 0.9070\n",
      "Epoch 30/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1561 - accuracy: 0.9338 - val_loss: 0.2990 - val_accuracy: 0.8670\n",
      "Epoch 31/120\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1653 - accuracy: 0.9297 - val_loss: 0.2342 - val_accuracy: 0.8920\n",
      "Epoch 32/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1420 - accuracy: 0.9432 - val_loss: 0.1938 - val_accuracy: 0.9200\n",
      "Epoch 33/120\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1312 - accuracy: 0.9488 - val_loss: 0.1890 - val_accuracy: 0.9160\n",
      "Epoch 34/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1248 - accuracy: 0.9498 - val_loss: 0.1711 - val_accuracy: 0.9340\n",
      "Epoch 35/120\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1230 - accuracy: 0.9526 - val_loss: 0.2234 - val_accuracy: 0.9100\n",
      "Epoch 36/120\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.1181 - accuracy: 0.9484 - val_loss: 0.1718 - val_accuracy: 0.9380\n",
      "Epoch 37/120\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1070 - accuracy: 0.9573 - val_loss: 0.1465 - val_accuracy: 0.9420\n",
      "Epoch 38/120\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0928 - accuracy: 0.9628 - val_loss: 0.1846 - val_accuracy: 0.9390\n",
      "Epoch 39/120\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.0932 - accuracy: 0.9608 - val_loss: 0.2260 - val_accuracy: 0.9130\n",
      "Epoch 40/120\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.0995 - accuracy: 0.9618 - val_loss: 0.2089 - val_accuracy: 0.9460\n",
      "Epoch 41/120\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.0922 - accuracy: 0.9642 - val_loss: 0.1145 - val_accuracy: 0.9580\n",
      "Epoch 42/120\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.0719 - accuracy: 0.9733 - val_loss: 0.1594 - val_accuracy: 0.9500\n",
      "Epoch 43/120\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.0739 - accuracy: 0.9707 - val_loss: 0.1383 - val_accuracy: 0.9500\n",
      "Epoch 44/120\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.0698 - accuracy: 0.9750 - val_loss: 0.1149 - val_accuracy: 0.9610\n",
      "Epoch 45/120\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0658 - accuracy: 0.9748 - val_loss: 0.1331 - val_accuracy: 0.9520\n",
      "Epoch 46/120\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.0667 - accuracy: 0.9773 - val_loss: 0.1386 - val_accuracy: 0.9580\n",
      "Epoch 47/120\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0628 - accuracy: 0.9768 - val_loss: 0.1706 - val_accuracy: 0.9500\n",
      "Epoch 48/120\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0632 - accuracy: 0.9758 - val_loss: 0.1424 - val_accuracy: 0.9520\n",
      "Epoch 49/120\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0630 - accuracy: 0.9761 - val_loss: 0.1340 - val_accuracy: 0.9500\n",
      "Epoch 50/120\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.0726 - accuracy: 0.9741 - val_loss: 0.1421 - val_accuracy: 0.9580\n",
      "Epoch 51/120\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0529 - accuracy: 0.9812 - val_loss: 0.1416 - val_accuracy: 0.9520\n",
      "Epoch 52/120\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0567 - accuracy: 0.9800 - val_loss: 0.1521 - val_accuracy: 0.9540\n",
      "Epoch 53/120\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.0489 - accuracy: 0.9815 - val_loss: 0.1611 - val_accuracy: 0.9530\n",
      "Epoch 54/120\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.0532 - accuracy: 0.9792 - val_loss: 0.1776 - val_accuracy: 0.9500\n",
      "Epoch 55/120\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0620 - accuracy: 0.9765 - val_loss: 0.1093 - val_accuracy: 0.9620\n",
      "Epoch 56/120\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0477 - accuracy: 0.9819 - val_loss: 0.1564 - val_accuracy: 0.9550\n",
      "Epoch 57/120\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.0598 - accuracy: 0.9794 - val_loss: 0.1580 - val_accuracy: 0.9540\n",
      "Epoch 58/120\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.0499 - accuracy: 0.9805 - val_loss: 0.1864 - val_accuracy: 0.9560\n",
      "Epoch 59/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0559 - accuracy: 0.9812 - val_loss: 0.1372 - val_accuracy: 0.9600\n",
      "Epoch 60/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0399 - accuracy: 0.9855 - val_loss: 0.1365 - val_accuracy: 0.9620\n",
      "Epoch 61/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0439 - accuracy: 0.9828 - val_loss: 0.1405 - val_accuracy: 0.9470\n",
      "Epoch 62/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0481 - accuracy: 0.9825 - val_loss: 0.2116 - val_accuracy: 0.9560\n",
      "Epoch 63/120\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.0474 - accuracy: 0.9820 - val_loss: 0.1341 - val_accuracy: 0.9670\n",
      "Epoch 64/120\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.0452 - accuracy: 0.9833 - val_loss: 0.1607 - val_accuracy: 0.9570\n",
      "Epoch 65/120\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.0464 - accuracy: 0.9835 - val_loss: 0.1398 - val_accuracy: 0.9640\n",
      "Epoch 66/120\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 0.0326 - accuracy: 0.9888 - val_loss: 0.1667 - val_accuracy: 0.9580\n",
      "Epoch 67/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 0.1278 - val_accuracy: 0.9680\n",
      "Epoch 68/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0449 - accuracy: 0.9871 - val_loss: 0.1153 - val_accuracy: 0.9680\n",
      "Epoch 69/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0325 - accuracy: 0.9893 - val_loss: 0.1168 - val_accuracy: 0.9630\n",
      "Epoch 70/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0326 - accuracy: 0.9880 - val_loss: 0.1226 - val_accuracy: 0.9700\n",
      "Epoch 71/120\n",
      "40/40 [==============================] - 2s 63ms/step - loss: 0.0371 - accuracy: 0.9884 - val_loss: 0.1175 - val_accuracy: 0.9690\n",
      "Epoch 72/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0258 - accuracy: 0.9900 - val_loss: 0.1148 - val_accuracy: 0.9720\n",
      "Epoch 73/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0329 - accuracy: 0.9884 - val_loss: 0.2657 - val_accuracy: 0.9360\n",
      "Epoch 74/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0529 - accuracy: 0.9838 - val_loss: 0.1211 - val_accuracy: 0.9690\n",
      "Epoch 75/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0238 - accuracy: 0.9908 - val_loss: 0.1123 - val_accuracy: 0.9710\n",
      "Epoch 76/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0287 - accuracy: 0.9892 - val_loss: 0.1959 - val_accuracy: 0.9580\n",
      "Epoch 77/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0320 - accuracy: 0.9892 - val_loss: 0.1412 - val_accuracy: 0.9710\n",
      "Epoch 78/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0234 - accuracy: 0.9918 - val_loss: 0.1604 - val_accuracy: 0.9680\n",
      "Epoch 79/120\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 0.1238 - val_accuracy: 0.9680\n",
      "Epoch 80/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 0.1323 - val_accuracy: 0.9660\n",
      "Epoch 81/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.1343 - val_accuracy: 0.9660\n",
      "Epoch 82/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0298 - accuracy: 0.9910 - val_loss: 0.1255 - val_accuracy: 0.9730\n",
      "Epoch 83/120\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 0.1615 - val_accuracy: 0.9660\n",
      "Epoch 84/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0205 - accuracy: 0.9941 - val_loss: 0.1249 - val_accuracy: 0.9730\n",
      "Epoch 85/120\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.1331 - val_accuracy: 0.9700\n",
      "Epoch 86/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.1325 - val_accuracy: 0.9720\n",
      "Epoch 87/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0267 - accuracy: 0.9910 - val_loss: 0.1077 - val_accuracy: 0.9760\n",
      "Epoch 88/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.1164 - val_accuracy: 0.9760\n",
      "Epoch 89/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 0.1574 - val_accuracy: 0.9640\n",
      "Epoch 90/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0217 - accuracy: 0.9924 - val_loss: 0.1620 - val_accuracy: 0.9680\n",
      "Epoch 91/120\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 0.1340 - val_accuracy: 0.9750\n",
      "Epoch 92/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 0.1512 - val_accuracy: 0.9710\n",
      "Epoch 93/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 0.1298 - val_accuracy: 0.9740\n",
      "Epoch 94/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.1382 - val_accuracy: 0.9740\n",
      "Epoch 95/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0244 - accuracy: 0.9918 - val_loss: 0.1347 - val_accuracy: 0.9700\n",
      "Epoch 96/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.0982 - val_accuracy: 0.9780\n",
      "Epoch 97/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.1325 - val_accuracy: 0.9760\n",
      "Epoch 98/120\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.0185 - accuracy: 0.9956 - val_loss: 0.1069 - val_accuracy: 0.9760\n",
      "Epoch 99/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.1036 - val_accuracy: 0.9760\n",
      "Epoch 100/120\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.1179 - val_accuracy: 0.9740\n",
      "Epoch 101/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.1389 - val_accuracy: 0.9720\n",
      "Epoch 102/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0279 - accuracy: 0.9932 - val_loss: 0.1008 - val_accuracy: 0.9780\n",
      "Epoch 103/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0316 - accuracy: 0.9915 - val_loss: 0.1189 - val_accuracy: 0.9720\n",
      "Epoch 104/120\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.1124 - val_accuracy: 0.9750\n",
      "Epoch 105/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0231 - accuracy: 0.9955 - val_loss: 0.1156 - val_accuracy: 0.9750\n",
      "Epoch 106/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.1060 - val_accuracy: 0.9760\n",
      "Epoch 107/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.1463 - val_accuracy: 0.9750\n",
      "Epoch 108/120\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.1632 - val_accuracy: 0.9690\n",
      "Epoch 109/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0288 - accuracy: 0.9923 - val_loss: 0.1296 - val_accuracy: 0.9750\n",
      "Epoch 110/120\n",
      "40/40 [==============================] - 2s 63ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.0898 - val_accuracy: 0.9790\n",
      "Epoch 111/120\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.0184 - accuracy: 0.9932 - val_loss: 0.1123 - val_accuracy: 0.9740\n",
      "Epoch 112/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0156 - accuracy: 0.9965 - val_loss: 0.1168 - val_accuracy: 0.9760\n",
      "Epoch 113/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 0.1190 - val_accuracy: 0.9740\n",
      "Epoch 114/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.1243 - val_accuracy: 0.9780\n",
      "Epoch 115/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.1419 - val_accuracy: 0.9750\n",
      "Epoch 116/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.1335 - val_accuracy: 0.9750\n",
      "Epoch 117/120\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0904 - val_accuracy: 0.9830\n",
      "Epoch 118/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0240 - accuracy: 0.9940 - val_loss: 0.1392 - val_accuracy: 0.9760\n",
      "Epoch 119/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0309 - accuracy: 0.9939 - val_loss: 0.0961 - val_accuracy: 0.9790\n",
      "Epoch 120/120\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.1045 - val_accuracy: 0.9710\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=256,epochs=120,validation_data=([inputs_test, queries_test], answers_test))  # , callbacks=[reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs_9710.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA/eklEQVR4nO3dd3zV5dn48c+VPUkgYYe9URQFUcSB1gGKs9W6d6lWrf5a+6iPo3s9HU+fLq1tHa2ideCoUgUVcKICorI3JMxAyF5nXL8/7m/MSTgJJ8BJck6u9+uV1znfdc79TeC+vvcWVcUYY0zXldDRCTDGGNOxLBAYY0wXZ4HAGGO6OAsExhjTxVkgMMaYLs4CgTHGdHEWCEyXIiKPi8hPIjx3s4icEe00GdPRLBAYY0wXZ4HAmBgkIkkdnQYTPywQmE7Hq5L5noh8LiJVIvJ3EektIv8RkQoReVNEuoecf76IrBCRUhFZICJjQo4dIyJLvev+BaQ1+64ZIrLMu/YDETkqwjSeKyKfiki5iBSKyA+aHT/J+7xS7/h13v50EfmNiGwRkTIRec/bN1VEisL8Hs7w3v9ARJ4XkSdFpBy4TkQmiciH3nfsEJE/ikhKyPVHiMg8ESkRkV0i8t8i0kdEqkUkL+S8CSJSLCLJkdy7iT8WCExn9VXgTGAkcB7wH+C/gXzcv9tvA4jISOBp4E6gJzAH+LeIpHiZ4kvAP4EewHPe5+JdeyzwKPBNIA/4C/CKiKRGkL4q4BogFzgXuEVELvQ+d6CX3j94aRoPLPOu+zUwATjRS9N/AcEIfycXAM973/kUEAD+H+53Mhn4CvAtLw3ZwJvA60A/YDjwlqruBBYAl4Z87lXAM6rqizAdJs5YIDCd1R9UdZeqbgPeBT5S1U9VtQ54ETjGO+/rwGuqOs/LyH4NpOMy2hOAZOB3qupT1eeBT0K+4xvAX1T1I1UNqOoTQJ13XatUdYGqfqGqQVX9HBeMTvUOXwm8qapPe9+7V1WXiUgCcANwh6pu877zA++eIvGhqr7kfWeNqi5R1UWq6lfVzbhA1pCGGcBOVf2NqtaqaoWqfuQdewKX+SMiicDluGBpuigLBKaz2hXyvibMdpb3vh+wpeGAqgaBQqC/d2ybNp1ZcUvI+0HAd72qlVIRKQUGeNe1SkSOF5H5XpVKGXAz7skc7zM2hLksH1c1Fe5YJAqbpWGkiLwqIju96qKfRZAGgJeBsSIyFFfqKlPVjw8yTSYOWCAwsW47LkMHQEQElwluA3YA/b19DQaGvC8EfqqquSE/Gar6dATfOwt4BRigqjnAw0DD9xQCw8JcsweobeFYFZARch+JuGqlUM2nCn4IWA2MUNVuuKqzA6UBVa0FnsWVXK7GSgNdngUCE+ueBc4Vka94jZ3fxVXvfAB8CPiBb4tIkohcDEwKufavwM3e072ISKbXCJwdwfdmAyWqWisik4ArQo49BZwhIpd635snIuO90sqjwG9FpJ+IJIrIZK9NYi2Q5n1/MnA/cKC2imygHKgUkdHALSHHXgX6iMidIpIqItkicnzI8X8A1wHnA09GcL8mjlkgMDFNVdfg6rv/gHviPg84T1XrVbUeuBiX4e3DtSfMDrl2Ma6d4I/e8fXeuZH4FvAjEakAHsQFpIbP3QqcgwtKJbiG4qO9w3cBX+DaKkqAXwIJqlrmfebfcKWZKqBJL6Iw7sIFoApcUPtXSBoqcNU+5wE7gXXAaSHH38c1Ui/12hdMFya2MI0xXZOIvA3MUtW/dXRaTMeyQGBMFyQixwHzcG0cFR2dHtOxrGrImC5GRJ7AjTG404KAASsRGGNMl2clAmOM6eJibuKq/Px8HTx4cEcnwxhjYsqSJUv2qGrzsSlADAaCwYMHs3jx4o5OhjHGxBQR2dLSMasaMsaYLs4CgTHGdHEWCIwxpouLuTaCcHw+H0VFRdTW1nZ0UqIuLS2NgoICkpNtDRFjzOERtUAgIo/i5kTfrapHhjkuwP/h5mSpBq5T1aUH811FRUVkZ2czePBgmk40GV9Ulb1791JUVMSQIUM6OjnGmDgRzaqhx4FprRyfDozwfmbiptQ9KLW1teTl5cV1EAAQEfLy8rpEyccY036iFghU9R3c7IotuQD4hzqLgFwR6Xuw3xfvQaBBV7lPY0z76cg2gv40XXGpyNu3o/mJIjITV2pg4MCBzQ8bY0yrdlfUsm1fDUcV5JKYcOgPU6pKeY2fLSVVbN5bjapyyoiedM9MAaDOH2DbvhoSREhMEJIS3Wt6ciLZaY3te1V1fj7eVMLuilpKqnxkpSZy2uheFHTP2O87g0GlPhAkLTnxkNPfXEcGgnB/jbATH6nqI8AjABMnTux0kyOVlpYya9YsvvWtb7XpunPOOYdZs2aRm5sbnYQZE0W+QJAdpbUUlVZT6wswolc2Bd3Tm5Rad5TVMOujreyprCM/K5Ve2akMystkaM9MKuv8vLO2mMWb95GXlcLQ/CyG98piTN9u9O6WioigqgSVJpl3rS9AYUk1W/ZWs3lvFZv3VrFhdxVFpdWoQlKC0Dcnna+M6cWEQd158dNtPPNJIfX+IPlZqZwzrg9HFeTSPzcdgPlrdvPWql3sKq+jzh8gqNAzK5XeOWkMy8/k6AG5jOiVxdpdFSzZWsranRVsK62hss7f5PeRmCBMGtyDal+AldvL8AXCZ1XDemYyaUgeZTX1vL16N7W+YNMTXl7B6D7Z9MtNJzUpgXp/kK0l1Wwtqeabpw7jO2eOPEx/wUYdGQiKcEsKNijALTsYc0pLS/nzn/+8XyAIBAIkJrYcvefMmRPtpJk4Fwy6zCbhAE+5DZNLNmTSlXV+Fq4p5sONe9iwu4pNe6rwBYJkpyWRk55M35x0+ndPp3e3VLqlJZOekkjRvho2FlexZW8V20pr2FVeS7BZXpedlsTQnlkM6pFBIKi8sWInQVV6ZKZQUlW/3/kAg/MyKN/ip6SqsYIgJz2ZxAShvMZHQJXuGSnkZ6VQXuNnZ3nTNrJu3nceO7A7iSL4gsq6XRX85LVVACQnCl89toDjh/Zg3spdPLu4kH982DjINjlROGFoHlNH9SIlKQEBiivq2FFWy7vr9zD7021fnts3J40j+uUweVgeBd3TGdAjg8F5mdT6AryxYidvr95NTnoyN0wZwsje2YiAP6gEg4o/qJTV+FiyZR+vfr6d1KRELpkwgGlH9mFwfibdM5LZUVbLW6t28c7aPRRXuMCUIMKQ/ExOG92L44f0aP0fxEHqyEDwCnCbiDwDHI9bQHu/aqFYcM8997BhwwbGjx9PcnIyWVlZ9O3bl2XLlrFy5UouvPBCCgsLqa2t5Y477mDmzJlA43QZlZWVTJ8+nZNOOokPPviA/v378/LLL5Oent7Bd2airbLOz+Y9VaQlJ9AzK43stCQCqvgCQTbvqWbVjnKKK+sY07cb4wtyqQsEWL6tjM8Ky1i6dR+fbi0lqMq4/jkcVZBDj8xUMlMT2VflY/GWEj4rLKWyzv/lU3WPzBR6ZKSwaU8V9YEg2alJDO+dxYnD80hPTqS81k9pdT3rdlewYO3+T6u9u7kn+snD8ijITaegewb9u7sn1zW7Kli9o4JNe6r4tHAflbV+rpk8mOunDGaAFxj2VNaxsbiKjXsqSUlM4KQR+fTNcf/OS6vrWburklU7ylm7q4IEEbLTkkhKTGBvZR17KuvISk1mUF4Gg/IyGNgjg0F5LgMN13ZWWFLNJ5tLOH5o3pdP/xcdU0CdP8D2UldVVOcPMGlIjybVNaFUle1ltazfXcnwXllffk44Rw/I5b+mjY7o7x4MKiL7t/kN65nFsJ5ZzDwl7HLTURO1aahF5GlgKpAP7AK+DyQDqOrDXvfRP+J6FlUD13tLB7Zq4sSJ2nyuoVWrVjFmzBgAfvjvFazcXn74bgQY268b3z/viBaPb968mRkzZrB8+XIWLFjAueeey/Lly7/s4llSUkKPHj2oqanhuOOOY+HCheTl5TUJBMOHD2fx4sWMHz+eSy+9lPPPP5+rrroq7PeF3q+JLWU1Phas2c2bq3azdMs+tpXWHNTniMCo3tlMHNydpIQEPi0sZdX2cuoDwSbHjxnYnbzMFBITBF8gyN7KevZW1TEkP5Mzx/bh2IG5JCWG7zOiqlTVByiv8VFd76dPTjpZqXEx9KhLEpElqjox3LGo/VVV9fIDHFfg1mh9f0eaNGlSk37+v//973nxxRcBKCwsZN26deTl5TW5ZsiQIYwfPx6ACRMmsHnz5vZKrmnB6p3lLNtaSq9uqfTKTiM9JZGkBK/xL8FlnssKS3lnXTErt5e7Bi6vTtsfVJIShGMG5nLisDwqav289sUO3lu3B39QyctMYcrwfK44fiBD8zOpDwQprqijotbvviNR6J+bzti+3eiZncqK7eV8VlRKalIi4/rnMLZft/0yZVWl1hekqt5PWnLiIWfaIkJWapJl/u2lai/UlkJe+5YGIE5GFodq7cm9vWRmZn75fsGCBbz55pt8+OGHZGRkMHXq1LDjAFJTU798n5iYSE3NwT0pmtb5AkE2Frv68G5pyfiCQRasKWb+6t10z0zh9tOHM6JXFo++v5lf/GdViw1+oTJTEjmqIJeUJBccEr1gUV3v57nFRV/WRxd0T+fGk4Zw1hF9GD+gbb1XpgzPZ8rw/FbPERHSUxJJTzn8vUpMlNXsg7+fAeXb4arZMHhKu3593AWCjpCdnU1FRfgV/8rKyujevTsZGRmsXr2aRYsWtXPq4puqotpyY2kwqHxaWMobK3by3ro9rNtdETZzH94ri2WFpbz6+XZG9c5m9c4Kzhzbm3umj6asxsfu8lrq/EECQcUfUAKqBILKyN7ZHDMwl+QWqlfq/UE+957kj+zfzcaBHA6+GtgwHwZMgszWg2NYWz6EnqMg4zA0vAZ8sOgh2L0KzvoJZOa1fG5dJRR9DANOgJSQ7qEBPzx3PZQWQrd+MOvrcN2/oVsBfPJXFxzO/Q0kpbb82YfIAsFhkJeXx5QpUzjyyCNJT0+nd+/eXx6bNm0aDz/8MEcddRSjRo3ihBNO6MCUxqZAUJs8PVfV+fm8qIzXl+9gzvKd+AJBLhzfn/OO7kvRvhreWbuH1TvLKa/1sa/KR2Wdn+RE4fghedx40lBG98kmPSXR9UgJKpOH5TEoL5N9VfU8/M4GZi/dxoMzxnL9lEOfsiQlKYGJg6PT06NT274Mls2CoM9tj7sUBk0Of275dsjqAwkRjG8NBmH2TFj1CiAw4HjoNcY1ioTK7gsjp0GfcY3HVGHBL2DhL6D7ELj6RejhVeGW74DKne69rxZKNsLe9e7avBHuO/oe3fR7Nr8Pr30HileDJMCmhXDJ49BjKKx9w10/5BQYNAXWvg6v3wPl2yC9B0z6Bow821336ZOwcT6c/0cYdho8Og2euAACdeBvqD1QdzxKDxIxt2bxgRqLu4KucL+qyqKNJTzyzgbmrymmW1oSfXLSqKoLfNnAmpqUwOmje5GQIMxbsevLhtLcjGTGD8ile0YK3dKSOHZQd04b3YtuLfQMMQcQDLiMbMipkJrl9qm6ffkjm9Zp15TC/J/CJ3+DpDRIyYT6KkhOh29/Cmk5TT/70yfh5Vuh/0SY8VvofSSsfhU++TvUeBMTZPaC0++H/sfCgl/Cgp/BSf8PElNh7X9cIAmlCtV7AXVP1aOmwahzYM0cl67RM2Dze+4Je/ovYeUrsPIl0Gb9+ROS3GdpwG0fdxNM/x9ISISP/wpzvge5A9y+7L7w7DVQVuR9juKGSqn7Pfhr3b2deDuseMmlO9Txt8D0X7j3ezfAc9dCv2Ng8u3wxbPwzq9g2i/hhJsP4g/otNZYbIEgBsXj/aoqDy3cwBMfbAYgqK4vd15mChcd05/6QJAdZbWkJycysncWI3tnM2V4PpleQ2ZpdT0L1xYzJD+TI/rlHJbRo51O1R6oKnZPnMEALHsKPnrYPRVf+Oem59ZXueqTze/CxBuhZ8ggpA/+AKnZcNRlkJzW+neqwqt3wpLHYfDJcOVzLlNf+CuY/xNAYMwMGH4GbFwA694EX5XLNE+7D9JzXengkVPh5O/CVx5s/OyVL8Nz10H/CbBvs8u8s/tBeRF0Hwy9xrrzti2Byt0w+lwXJI6+HC58qPWn48piWPcGrJ7jnrZ91W7/lDvhjB+4p/h/XgwV2yG1G0y4DgZOdp+ZkOxKCrmDAHVpW/wYLPoTHHER5A13GfOoc+Crf2+s5qkpdftTsmDUdMgfARsXwvo3XVXUxBsh0auE2bMe9q5z71MyYdBJLZeIgkH411Uu8F71gis1HAQLBHEmHu5XVams85OdlowvEOT+F5fzr8WFnDwin/656fiDyrEDu3Pxsf2jMqS+XQW9J80DVX2U73BPf8GAy5BGz3CZCbjM9InzoK7cVSckpbnMLTnDZczf29CYMX72DLzybVe1ADDsdFcNArDlA3hsunuf2RPGXwFpuW67x1AY/hUXJMAFgXkPwge/hxFnwbp5rrplyCnwxr0w7hLIHeiesmvLIKu3Oz7xBug3vum9vfANV51z+1LI6e8y6GevcUHg6tkQqIf5P4c9a2Hi9e7eE7y/e22ZO/bxX6DfsXDdawcOYKF8NS5DTkiEEWc27i/bBhvehrHn719SCef9/3O/D4DxV8F5/9eYsUdbXQX8/WwYf7krVRwECwRxJtbvd1d5Ld96ailLtuwjPyuV7LQkNu2p4vbTh/OdM0fGV4NqMAhPXgyo6w2S0EJQC/jgr6fDzs8b9yVnuMym3zGu3jg5HU77b/eEWrUHxn0NdnwOr98N310D2X3cdY9Oh8pdcN7voOgTeOtHcMNcGHg8PD4Dite4EsRHD7un1VCJKa6EkdoN6itdvfdxN8E5v3YZ/py73HmjZ8AlT7iMsK4SSrdCz9EtB7t9W+CPE92TckISLH8B+hwF1/7blRoisW+LaxxOyTzwudGy4kUXsE+4JWr19S3y1bYtADbTIeMIjAnn400l3DprKVV1fm47bTi7ymvZWlLNt6YO45KJAw78Ae2hrf/hgkFXHdLwJB3qs6dd1QTAx4+4DEQV5t7vMuSLH3G9Vz74vQsClzwOI6e7KqDZM2H2NyAl2wWBa17ev495Q732zuUuEASD7nPGX+Ge3PtPcL1aFvwMTr7LVRWd/XP3ZDziTPDXu8/QIGz/1NWjb/nAVXMAnHCr6w0j4ho4wZ137m8bn4ZTs6D32NZ/R90HwaSZ8OEfXd3+1P+GKXe07ffcfVDk50bLERd13HcfQhA4EAsEJmp8gSBLt+xj/ppiPt26j3W7KympqmdIfiZP3XQ8I3uHyTib27PO1Wmf8YPD093vQDa9C09+1dVln3hby+epumqFFS+6HiL1VXDbJ67ao0FNqatKKJjknnrf+pGrOln8qMsQEVdNM+3nrjfL2AsbM5rcAe5p+e0fu++47KnwA416e+Nmdi2HEWe4nir1ldB3vNufkuky3Ln3Q8km1ztn4vWN1yelNL4fPOXA/dcbgsHBOPW/XEnjqEtcNZTpNCwQmKhYsGY3d/5rGaXVPpIShCP753DmmN6M6pPNVycUkJPu9eBRdQ2RQ04J87Sr8PJtULjINSR+/Un3ZFpdAkufcA186d1bToSqq84YOBn67LdI3v6CQZh7n6uvnnufe8KfcO3+55VshDn/BevnuYxt6FSvp8vf4IzvN543/2cu3VfPhox8+PMJLuOv2AHHfQPGXgBPXw7/vMh1KTznV02/JzEJzvyh+2lJenfXM2bXcre9Y5l7Da2jn3gjvP97KN3iep4kd9AcVmk5MPXujvlu0yoLBIfBwU5DDfC73/2OmTNnkpGx//zjsaSqzv9lD57Xl+/k9qeXMqJXNr+4eBxThue3OKkXa/7jeqXkDISZ85sOEPrsGRcEBp/sMtrFf3dP1P+8GPascb1Urnyh5Qa7d37lujKmZLsn6qGntn4Ty1+AHZ+5/torX4J/3+Ea6QafBDkDoPAjWPMafPG8q+c++2cuQ09KgWeuhCWPwSnfc71Iti9zg4Em3uD6nwOc9WP3mUd93euGmADXv+a6T556N2T1asNvPESfI13VELjvTUqH/FGNx1MyXIlqyeMueBrTjDUWHwahk861VcPEc/n5kY+Q7Oj7DVVTH+C+F79g9qfbGNgjg6MH5DLnix0cVZDD49dPanzyDyfgh4cmu14dVcVeD5KXXMZaWwZ/mOh6pdw4F2Zd6qptMvJc1cex17jqlYb+18GA63GSO8hlfKv+7brcjb3AVS/tXQ9T73Hv177hvj9/hOuieOw1rorlDxMhPQdmvuP6fT/1NdjyftM0p3aDMee5fu3d+jXu3/w+PH4OzPid603zyKmuuuiWDxqrtFTdE3vvcYe3t8lbP4b3/hfu2+FKF4F6uOnNA19nuhRrLI6y0GmozzzzTHr16sWzzz5LXV0dF110ET/84Q+pqqri0ksvpaioiEAgwAMPPMCuXbvYvn07p512Gvn5+cyfP7+jb6VNCkuq+eY/l7BqZzlXHD+Q3eV1LFyzm5OG5/OnK4898GRln/7TZd5ff8oFg9k3wQs3uF4rWxe54HDFv1xPmwsfgodPgqDfdR/se5Rr4Fz0Z9i3CYoWQ/Ue161y6FQXNPpPgIseAX8NzLrM1dGnd3ddIZPTXV/uL55zT/I9hkLZVjj/JfeknpLh6uiL17g0lm51o1QHTWlar95g0ImuF8yih1xa9m6Aa19p2q4h4noAHW69j3CDnnavdL2Ijr7s8H+HiWvxFwj+cw/s/OLwfmafcY2j/sL4xS9+wfLly1m2bBlz587l+eef5+OPP0ZVOf/883nnnXcoLi6mX79+vPbaa4CbgygnJ4ff/va3zJ8/v00lgo60akc5zy8p4uNNJazYXkZmahKPXnscp4121RqqGln3z7pKWPBzN+/K6HNdJrl3HSz8pXuaBzjx2240Kbhqk2++C4nJjZnrmT92T/pbPnQ9YIae6qpI1vzHnfP1p1xPi+Q0l6nvXe9GwoY+jdeWwZInXFfKUec2HayTkOh6wxyoRwy49J/wLXjpZldtdfJdrt2jPfQZ515XvgL1Ffv34TfmAOIvEHSwuXPnMnfuXI45xj35VVZWsm7dOk4++WTuuusu7r77bmbMmMHJJ5/cwSltmw3FlfzvvLW8+vkOUpMSOGZgLredPoJLJhQwoEdj+0bEYwA++Zvr697QAAyuj/yUO7wukdI4nUGD7N5NtxOT4Ipn8Wada9w//ZfuM0L77CelhM/Q03Jgyrfdz6FWkx55Mbz9E8gpgKn3HtpntUWPoa5d4LOn3XZDjyFjIhR/gaCVJ/f2oKrce++9fPOb39zv2JIlS5gzZw733nsvZ511Fg8++GCYT+hcVJUnF23hR6+uJDkxgdtOG843Th5KTsYB5u3x18P2pa6hNFwvlY0L3JPsgElN97d1sJBb5inMvoMYjXyoA4SSUuHmd11vo/YacQou4PUa437fialuOgNj2iD+AkEHCJ2G+uyzz+aBBx7gyiuvJCsri23btpGcnIzf76dHjx5cddVVZGVl8fjjjze5tjNWDVXU+vj+yyuY/ek2ThvVk//52tH0zI5gKtzN78Fr33XzuWT2dAOJjrtp/0bTMedFNf0doj3GOoTT+wgXCPoc6arPjGkDCwSHQeg01NOnT+eKK65g8mQ35W5WVhZPPvkk69ev53vf+x4JCQkkJyfz0EMPATBz5kymT59O3759O0VjcXW9n9+9uY731+9h1Q636tZ3zhzJbacNP+AC6YCrGnnnV663z7m/cT105v/UTYB2gzfjYulWtxCHVWEcPg3tBPY7NQfBAsFhMmvWrCbbd9xxR5PtYcOGcfbZZ+933e23387ttx/cJFKHW70/yC1PLuXddcWcMDSP204bzuljejN+QG74C6r2uqqchqHvAb/rNTNyGnztMdfz5rib4O2fuuBQs8/12gk36MkcmoZAYL9TcxAiWAnCxLOKWh/+QJBgULnruc9YuLaYn100jlnfOIHvnDWq5SDgq4U/Hw9vhYx63b3C9fEfd0nTFZiGTgXUzWEDbtBWQhL06vhlRePGgBPcBHVHfq2jU2JikJUIurBZH23l/pe+QETonpHMnsp67p42mssmDTzwxWtfd/381/zHzZUDru8/wMBmq7AVTHT9+ze/57qKbl/mGjejOIlWl5OQYKOGzUGLm0AQcf/1GHe4RoIvWLObB15ezglD8zh2YHe2ldZwdEEO1544OLIP+OwZ97pvk5t7p8dQ2Pqhm4ohp6DpuUmprnfQpncbG4pHnXNY7sMYc+jiIhCkpaWxd+9e8vLy4joYqCp79+4lLe3QnqRXbi/n1qeWMqp3Nn+9ZuKXcwRFrGqPm3Bt5HS35N6G+W4N2K2L3Lw84Qw+xTUa7/zCTcTWMP+OMabDxUUgKCgooKioiOLi4o5OStSlpaVRUFBw4BPDqPUFeOz9zfxp/nqy05J59Lrj2h4EAJbPdlM9nH6/m/Vyw9tuqcKKHW56iHAGnwSomxICojPVgjHmoMRFIEhOTmbIkCEdnYxObd2uCq5//BOK9tVwxphePDjjCPrkRFiyCAbg9Xvc4tvHXO1GsPYe5/qsDzvNLca9+T137sDJ4T+j/wQ3+vWL59xgr97WUGxMZxEXgcAc2G/mrqW8xsdTNx3PlOFtHLy2e6VbXQvc1BA7P3erVoFbD3fpP9yTfmqOawQOJynFLZW4cYELKB01J74xZj/WfbQL2LSnijdW7uTqyYPaHgSgsTfQGT+A8u2QkOy6iAIMORUQV0U0YFLLa/KCW1cAbNCTMZ2MlQi6gL+9u5HkhITIewQ1t3URZPeDKXfChOuhYmfjQukZPdwModuW7N9ttLmG2Tht0JMxnYqVCOLc3so6nl9SxEXH9KdX9kH2Ntq6yGXyIm7t3V6jmx4fdrp7bal9oEHBcW59gPFXHFw6jDFRYSWCOPePD7dQ5w/yjVMO0Ji+6t9utPBRlzTdX1oI5UUw8I7w14ErJQT9+88k2pwIHP31yBJujGk3US0RiMg0EVkjIutF5J4wx7uLyIsi8rmIfCwiEawwbiJV7w/y5KItfGV0L4b3ym795IX/4/r5N9fSaOFQOf1d+4HNemlMTIpaIBCRROBPwHRgLHC5iDRfGeS/gWWqehRwDfB/0UpPV/TO2mL2VtVz5QkHmDIiGHBLMu7b7JaMDLX1Q7f4u3X3NCZuRbNEMAlYr6obVbUeeAa4oNk5Y4G3AFR1NTBYRJotQ2UO1kvLttEjM4WTR/Rs/cSSTRCoA9Qt7h5q66ID9wYyxsS0aAaC/kBhyHaRty/UZ8DFACIyCRgE7DdsVkRmishiEVncFUYPHw4VtT7mrdzFjKP6kpx4gD/z7hWN74vXNL6v2efGEByoEdgYE9OiGQjCTfrTfMa0XwDdRWQZcDvwKeDf7yLVR1R1oqpO7NnzAE+3BoDXl++kzh/kklFJboH21uxeBXjLOxavbtxf+AmgB+4WaoyJadHsNVQEDAjZLgC2h56gquXA9QDiZovb5P2YQ/Tysu0c372CI2efAf4aGDQFjvwqHHvN/mvz7l4J3Qe7xt7QQLD1Q7duQP8J7Zp2Y0z7imaJ4BNghIgMEZEU4DLgldATRCTXOwZwE/COFxzMIdhVXsv7G4r5n5S/Iygcf7ObEO7f34aP/7r/BbtXucbgnqOaVg1tegf6Hdt0kRljTNyJWiBQVT9wG/AGsAp4VlVXiMjNInKzd9oYYIWIrMb1Lmqls7qJRDCo/O7NtVySsIBBZR/DmT+Es38Kt34MI86Gufe7qaAb+Gph7wY3R1DP0W5tAX+dq07avtRbXcwYE8+iOqBMVecAc5rtezjk/YfAiGimoSup9QW485llfLpiJQszZ0HBSTDhBndQBC78Mzw0BZ6/AWYucOsN71kLGnCBQNW937vBdSXVIAw9tSNvyRjTDmyKiTixZMs+vv6XD3lj5U4eHvM5acFaOP/3bgnDBpn5cPEjrovomz9w+3avcq+9xrqqIXDtBJsWummjC45r1/swxrQ/CwQxbt2uCq7++0d89aEPKNpXw0NXTuCYrH1uuci8YftfMPRUmHg9LH4MSre6huKEZMgb7n4kwbUTbFwIgya7ZSaNMXHN5hqKYcUVdVz194+o9we5d/porp48iIyUJPhoK+S2Mpr45Lvg0yfhnV+7mUTzR7oeQ4nJrvfQpnegeBUcfVm73YsxpuNYIIhRvkCQW59aSlmNj9m3TGFsv26NB0u3Ns4IGk5Ofzj2WljyGKRkuWUmG/QcDWu8Zh1rHzCmS7CqoRikqvz0tVV8vLmEX371qKZBwF/nnvJbKxEAnPwdN4CstrTpqmIN7QRpudDnqMOddGNMJ2SBoJP6vKiUzXuqmuyr9weZvbSIGX94j8c/2MwNU4Zwwfhms3aUFQF64EDQrR9MuM697xUyF2BPb62BISfb/ELGdBFWNdQJzV2xk289tZTEBOH+c8dw1QmDeGvVbn706kq2llQzvFcWP794HJdOHLD/xaVb3WtOmGPNnXq3awwOrQJqCAo2fsCYLsMCQQfyB4K8vGw7/1i0hQHd07nxpCHsq67n1llLObJ/DjnpyTzw8gr++u6mLwPAo9dN5LRRvZDm00Q0KPPm+TtQiQAgMw/O+nHTfX3GwWVPN203MMbENQsE7eiD9Xt48JUVBINK725pFJVWU1hSw/BeWSxcW8yrn+9ABI7sl8MTN0wiOzWJxz7YzGPvb+L+c8dw7YmDDzyTaOlWV/ffrflErxESgdHnHNy1xpiYZIGgHQSCyu/fWsfv317HkLxMxvTtxs7yWvrnpvPAuWM5Y0xvanwBnltcyOfbynhwxlhy0t1qXzeeNIQbTzrAMpOhSre6+v9E+9MaYyJjuUWUlFTV8+GGvby7rph31hazvayWrx5bwI8vPML19W8mMzWJ66a0IcNvSWlhZNVCxhjjsUBwmD25aAuzPtrKyh1uEtXstCSmDMvn/hn9OGdc3+gnoHSr6/FjjDERskBwmKgq/ztvLb9/ez3jB+Ry11kjmTwsn6MLckg6UL3+oX+5q9sP+KBiu5UIjDFtYoHgMFBVfjZnFX99dxOXHTeAn140jsSEFnr1HE51lfDCjVBdAjfOhfJtbsbQSLqOGmOMxwLBIdpXVc9/vfA581bu4roTB/PgjLEktEcQqNoLsy6BbUvc9o5lUFfh3luJwBjTBhYIDsHizSXc/vSn7Kms44EZY7lhyuCW+/cfLvu2wNrX4aO/uBLAhQ/BK9+G5S80jgq2QGCMaQMLBAcpEFRufnIJGSlJzL5lCuMKcqL7hfVV8MI3YM1rbjt/FFz9Igw6EVa+DMtfhPFXAHLwYwiMMV2SBYKDtGTLPvZU1vPHK46IfhCoLoFZl7pqoFPvgXGXQP7wxuNHftWVElbMdmMIklJa/ixjjGnGAsFBmrdyJz0Sqzl1aPbh+9CAH6r3QHafxn27V8Nz10LJJrj0nzBmxv7XjTrHrSa2dz0MnHz40mOM6RJs9tGDoKrMW7GTV9N/SPa7P2395JpSeP1eePEWqK9u+bzCT+CvU+E3o+Cxc2H1HJj3fXh4iptW+qoXwgcBgNQsGHm2e289howxbWQlgoOwobgS/76t9EstbJztM5wvnndBoKrYbZdsgMufgYwebttX61YDW/48fP4vyO4HJ/0/+PxZeOZyd874q+DMH7r1hltz5Fdh5UvWUGyMaTMLBAdh7spdTBJv0ffasvAnbV/m+vj3OwaufNYFjBdugsemQ8FE2LMedn4BvipIzoTJt8HUeyA1G067z9X5Z/d150ZixFkw4mwYceZhuUdjTNdhgeAgzFu5i1uyN0IdUNdCINj8nnu9/BlX59/vGLfq1/M3wNo3IG+E6+UzchoMPgmS0xqvTUyGMee1LVHJaS7gGGNMG1kgaKPdFbUsKyxlUk5DiaA8/ImFH0HuoKYNv0NPhe+td9NBGGNMJ2GNxW20cE0xPXUfubWFkJgSvmpI1QWCAcfvf8yCgDGmk7FA0Eab91ZxQtIatzH4JDetg2rTk0q3QuUuGDCp/RNojDFtZIGgjXaU1XJq6lpIyXKBQANu1G+owo/dqwUCY0wMsEDQRjtKazmOVa7aJ93rBtq8eqjwI9cTqNcR7Z9AY4xpIwsEbVRdtpuBgS1ujp80b2qJumYNxoUfQcEEWy7SGBMTLBC0gapSUL7MbQyaAmnd3PvQEkFdJexaEb6h2BhjOqGoBgIRmSYia0RkvYjcE+Z4joj8W0Q+E5EVInJ9NNNzqEqrfYzWDQQl0Y0LSPVKBKFdSLcvde0GFgiMMTEiaoFARBKBPwHTgbHA5SIyttlptwIrVfVoYCrwGxHptFNn7iirZaQUUZ050A3gClc1VPiRe410RLAxxnSwaJYIJgHrVXWjqtYDzwAXNDtHgWxxq7lkASWAP4ppOiQ7ymoYIUX480e5HV9WDZU2nlT4iVsrIL17u6fPGGMORjQDQX+gMGS7yNsX6o/AGGA78AVwh6oGm3+QiMwUkcUisri4uDha6T2gXSVlDJJdJPX2CjZpYaqGygohb/j+FxtjTCcVzUAQbghts5FXnA0sA/oB44E/iki3/S5SfURVJ6rqxJ49ex7udEbMt2s1iaJkFBzpdiSlQUJy08biqmLI6rg0GmNMW0UUCETkBRE5V0TaEjiKgNDJ8QtwT/6hrgdmq7Me2ASMbsN3tKvEvW5EcUKvMW6HiKseamgjCAagei9kWiAwxsSOSDP2h4ArgHUi8gsRiSSz/gQYISJDvAbgy4BXmp2zFfgKgIj0BkYBGyNMU7vLLluHn8SmVT9pOY1VQ9UloEELBMaYmBJRIFDVN1X1SuBYYDMwT0Q+EJHrRSS5hWv8wG3AG8Aq4FlVXSEiN4vIzd5pPwZOFJEvgLeAu1V1z6HdUvTk12yiOKWg6ZrAqd0aq4YaFqCxQGCMiSERD30VkTzgKuBq4FPgKeAk4Fpc18/9qOocYE6zfQ+HvN8OnNXWRHcEVaXAv4XSbmPpG3ogLaexaqhqt3u1QGCMiSGRthHMBt4FMoDzVPV8Vf2Xqt6O6/YZ90rLyhjAbmpyRzY9kNatsWqoyivMZPVq38QZY8whiLRE8EdVfTvcAVXtEiOn9m1dQXdRpKGhuEFqjlUNGWNiWqSNxWNEJLdhQ0S6i8i3opOkzqlm23IA0vo1m1E0tGqocjdIoluS0hhjYkSkgeAbqlrasKGq+4BvRCVFnZTuXk29JtJjYLMSQVo3qK+EgN+VCDJ7QoLN5WeMiR2R5lgJ3jQQwJfzCHXaOYGiIb10LZu1L/k5zZpEQucbqtpj1ULGmJgTaSB4A3hWRL4iIqcDTwOvRy9ZnU9u5Qa2Jg0kMaHZgOlUbyB0XbnrNWSjio0xMSbSxuK7gW8Ct+CmjpgL/C1aiep0ggG6+3ayL3Pq/sdC1ySoKrZ5howxMSeiQOBNBPeQ99P11JWTgCIZPfY/9uXEc2VQWWxVQ8aYmBNRIBCREcDPcesKpDXsV9WhUUpX5+J1D03JDDO1dEPVUPkO8NdYIDDGxJxI2wgew5UG/MBpwD+Af0YrUZ2Nv2ofAAnpufsfbCgRlGxwrxYIjDExJtJAkK6qbwGiqltU9QfA6dFLVufir3aBINiwNGWohkCwd717tUBgjIkxkTYW13pTUK8TkduAbUCXmUfBX1UKgKbtt1QCpGa714ZAYL2GjDExJtISwZ24eYa+DUzATT53bZTS1OkEvBIB4aqGEpMhORP2erNnW4nAGBNjDlgi8AaPXaqq3wMqcYvJdCmB6lIAJC1M1RC4LqQVO9x7CwTGmBhzwBKBqgaACaEji7uaYE0ZARWS0sNUDUFjO0FqDiSltl/CjDHmMIi0jeBT4GUReQ6oatipqrOjkqrOpnYfFWSQmtzCr6uhC2lmfvulyRhjDpNIA0EPYC9Newop0CUCgdSWUa4ZpCYlhj+hoRHZ1iEwxsSgSEcWd7l2gVBSW04ZmaQmt1CT1lA1ZCUCY0wMinRk8WO4EkATqnrDYU9RJ5RQX0a5ZpKd1EIg+LJqyEoExpjYE2nV0Ksh79OAi4Dthz85nVNiXTnldCe/xaqhhhKB9RgyxsSeSKuGXgjdFpGngTejkqJOKMlXTpkWkNZi1ZA1FhtjYtfBLqU1Ahh4OBPSmSX7Kigns+XG4lRrLDbGxK5I2wgqaNpGsBO3RkH889eTFKjxeg21VCLIda9WNWSMiUGRVg1lRzshnZY3BXU5GS33Gho0GUadC33GtWPCjDHm8IioakhELhKRnJDtXBG5MGqp6ky8QFCmmaQktvDryimAy2c1TkBnjDExJNI2gu+ralnDhqqWAt+PSoo6m9pSAKokk6SWAoExxsSwSHO2cOdF2vU0tnmBoC7JnvaNMfEp0kCwWER+KyLDRGSoiPwvsCSaCes0vKqhmkQLBMaY+BRpILgdqAf+BTwL1AC3RitRnYoXCOqtRGCMiVOR9hqqAu6Jclo6p5pSAOqTW5iC2hhjYlykvYbmiUhuyHZ3EXkjguumicgaEVkvIvsFEhH5nogs836Wi0hARHq06Q6irbYMH8mQlNbRKTHGmKiItGoo3+spBICq7uMAaxZ7K5v9CZgOjAUuF5Gxoeeo6q9UdbyqjgfuBRaqaknkyW8HtWVUJ2SSmtzCqGJjjIlxkQaCoIh8OaWEiAwmzGykzUwC1qvqRlWtB54BLmjl/MuBpyNMT/upLaVKLBAYY+JXpF1A7wPeE5GF3vYpwMwDXNMfKAzZLgKOD3eiiGQA04DbWjg+s+H7Bg5s5ymOasuolMyWp5cwxpgYF1HupqqvAxOBNbieQ9/F9RxqTbg1jlsqRZwHvN9StZCqPqKqE1V1Ys+e7TyfT20Z5WS1POGcMcbEuEgnnbsJuAMoAJYBJwAf0nTpyuaKgAEh2wW0vIbBZXTGaiGAmlIq6NvyPEPGGBPjIs3d7gCOA7ao6mnAMUDxAa75BBghIkNEJAWX2b/S/CRvDqNTgZcjTnV7qi2jrLWZR40xJsZF2kZQq6q1IoKIpKrqahEZ1doFquoXkduAN4BE4FFVXSEiN3vHH/ZOvQiY641V6FxUobaMfdrKWgTGGBPjIg0ERd44gpeAeSKyjwiWqlTVOcCcZvsebrb9OPB4hOloX74aCPooJb3l1cmMMSbGRTqy+CLv7Q9EZD6QA7wetVR1Ft6EcyWBDDKtRGCMiVNtnkFUVRce+Kw44c0zVBLIoIe1ERhj4pTlbq2JZHUyY4yJcZa7tcabcM6tV2xVQ8aY+GSBoDVflghsZLExJn5Z7taakPWK02yuIWNMnLJA0Bqv11AFNqDMGBO/LHdrTW0ZwcQ0fCRZIDDGxC3L3VrjqyaQnAlg01AbY+KWBYLW+GoIJLqVyaxEYIyJV5a7taa+ygKBMSbuWe7WGl8N/sR0AOs1ZIyJWxYIWuOrwZdgJQJjTHyz3K01vip8CamANRYbY+KXBYLW+GqoT3BVQ1YiMMbEK8vdWuOrpl68EoEFAmNMnLLcrTX11dRKQxuBVQ0ZY+KTBYLW+GqoI5UEgeRE6ejUGGNMVFggaIkq+KqplVRSkxIRsUBgjIlPFgha4q8FlBpNtUVpjDFxzXK4lvhqAKgm1RqKjTFxzXK4lviqAajRZGsoNsbENQsELal3gaBKrURgjIlvlsO1xNcQCFJsniFjTFyzQNASr42gMphiJQJjTFyzHK4lvioAKgMp1mvIGBPXLIdriVciqAhaY7ExJr5ZIGhJQyDwW9WQMSa+WQ7XknpXNVQeSLZAYIyJa5bDtcQrEZQHkqzXkDEmrkU1EIjINBFZIyLrReSeFs6ZKiLLRGSFiCyMZnraxGss3uezEoExJr4lReuDRSQR+BNwJlAEfCIir6jqypBzcoE/A9NUdauI9IpWetrMVwOSSJVfbHUyY0xci+aj7iRgvapuVNV64BnggmbnXAHMVtWtAKq6O4rpaRtfDZqcQZ1frURgjIlr0czh+gOFIdtF3r5QI4HuIrJARJaIyDXhPkhEZorIYhFZXFxcHKXkNlNfBSkZqNrqZMaY+BbNHC7cBP7abDsJmACcC5wNPCAiI/e7SPURVZ2oqhN79ux5+FMajq8GTWpYr9iqhowx8StqbQS4EsCAkO0CYHuYc/aoahVQJSLvAEcDa6OYrsj4qgl6gSDNRhYbY+JYNHO4T4ARIjJERFKAy4BXmp3zMnCyiCSJSAZwPLAqimmKnK+agJUIjDFdQNRKBKrqF5HbgDeAROBRVV0hIjd7xx9W1VUi8jrwORAE/qaqy6OVpjbx1RBM9BautxKBMSaORbNqCFWdA8xptu/hZtu/An4VzXQcFF81/mTXHmGNxcaYeGY5XEvqq/EnpgJWNWSMiW8WCFriq8GX4FUNWYnAGBPHLIdria8aX4LXWGwji40xccwCQUt81dQnNFQN2a/JGBO/LIcLJxgEfy11YuMIjDHxz3K4cPxuCuo6SQGssdgYE98sEIRTXw1AHdZYbIyJf5bDheNzgaBWrPuoMSb+WSAIxwsENepVDVkbgTEmjlkOF44XCKqxXkPGmPhnOVw43nrF1ZpKSmICIuFm1DbGmPhggSAcr7F4exX0zknt4MQYY0x0WSAIx6sa2lAaZESv7A5OjDHGRJcFgnC8qqF1JUFG9Mrq4MQYY0x0WSAIx1cFQHkgmeEWCIwxcc4CQTgNjcWkMqK3VQ0ZY+KbBYJwvEBQS4qVCIwxcc8CQTj1Vfglmd45mWSlRnURN2OM6XAWCMLx1VBDKsOtWsgY0wVYIAhDfdVUBVOsx5AxpkuwQBBGdVUF1WqBwBjTNVggCKO6qoIaUhnR2wKBMSb+WSAIo6660rUR9LQ2AmNM/LNAEIa/thJ/Yjo5GckdnRRjjIk6CwRhBOtrSErN6OhkGGNMu7BA0IyqkuivJiXd2geMMV2DBYJmFm/ZRyp1ZGR26+ikGGNMu7BAECIQVH747xVkSD2D+uR1dHKMMaZdWCAI8eziQpZvKydL6khOy+zo5BhjTLuwQOApq/HxqzfWcMKgbBLUD8kWCIwxXUNUA4GITBORNSKyXkTuCXN8qoiUicgy7+fBqCVGFXat3H+/vw6A/523ltLqer4/fajbn5wetaQYY0xnErVAICKJwJ+A6cBY4HIRGRvm1HdVdbz386NopYfPnoaHp8DSfzbu++gv8LP+7Hr1J/zjw01ccfxAxlQscsfSrLHYGNM1RHOO5UnAelXdCCAizwAXAGEey9vBmPPhi+fgldvwVRQjviqS3vs12q2A3ot/xU/TzuHCnlPhhbthwAkw9sIOSaYxxrS3aAaC/kBhyHYRcHyY8yaLyGfAduAuVV3R/AQRmQnMBBg4cODBpSY1Cy7/F74XZpI8/4cArC+4iEVj7qP2Pw9wU9IcmDcHRk6Drz0GKTagzBjTNUQzEEiYfdpseykwSFUrReQc4CVgxH4XqT4CPAIwceLE5p8RMU1M5k7frYwMJJDbrRvfX38GrF/L5CF3cOP405DybXD6A5BoU0sYY7qOaAaCImBAyHYB7qn/S6paHvJ+joj8WUTyVXVPNBL06PubeW35bo6afh/XnDKUXst38tySIh6YMRbJnxyNrzTGmE4vmoHgE2CEiAwBtgGXAVeEniAifYBdqqoiMgnXeL03GolZvLmEn89ZxVljezPzlKGICNPH9WX6uL7R+DpjjIkZUQsEquoXkduAN4BE4FFVXSEiN3vHHwa+BtwiIn6gBrhMVQ+66qc16SmJTB6Wx68vPRqRcLVWxhjTNUmU8t2omThxoi5evLijk2GMMTFFRJao6sRwx2xksTHGdHEWCIwxpouzQGCMMV2cBQJjjOniLBAYY0wXZ4HAGGO6OAsExhjTxVkgMMaYLi7mBpSJSDGw5SAvzweiMo9RB4mn+7F76ZzsXjqng7mXQaraM9yBmAsEh0JEFrc0si4WxdP92L10TnYvndPhvherGjLGmC7OAoExxnRxXS0QPNLRCTjM4ul+7F46J7uXzumw3kuXaiMwxhizv65WIjDGGNOMBQJjjOniukwgEJFpIrJGRNaLyD0dnZ62EJEBIjJfRFaJyAoRucPb30NE5onIOu+1e0enNVIikigin4rIq952TN6LiOSKyPMistr7+0yO4Xv5f96/r+Ui8rSIpMXSvYjIoyKyW0SWh+xrMf0icq+XH6wRkbM7JtXhtXAvv/L+nX0uIi+KSG7IsUO6ly4RCEQkEfgTMB0YC1wuImM7NlVt4ge+q6pjgBOAW7303wO8paojgLe87VhxB7AqZDtW7+X/gNdVdTRwNO6eYu5eRKQ/8G1goqoeiVte9jJi614eB6Y12xc2/d7/n8uAI7xr/uzlE53F4+x/L/OAI1X1KGAtcC8cnnvpEoEAmASsV9WNqloPPANc0MFpipiq7lDVpd77Clxm0x93D094pz0BXNghCWwjESkAzgX+FrI75u5FRLoBpwB/B1DVelUtJQbvxZMEpItIEpABbCeG7kVV3wFKmu1uKf0XAM+oap2qbgLW4/KJTiHcvajqXFX1e5uLgALv/SHfS1cJBP2BwpDtIm9fzBGRwcAxwEdAb1XdAS5YAL06MGlt8Tvgv4BgyL5YvJehQDHwmFfN9TcRySQG70VVtwG/BrYCO4AyVZ1LDN5LMy2lP9bzhBuA/3jvD/leukogkDD7Yq7frIhkAS8Ad6pqeUen52CIyAxgt6ou6ei0HAZJwLHAQ6p6DFBF5646aZFXd34BMAToB2SKyFUdm6qoitk8QUTuw1UXP9WwK8xpbbqXrhIIioABIdsFuGJvzBCRZFwQeEpVZ3u7d4lIX+94X2B3R6WvDaYA54vIZlwV3eki8iSxeS9FQJGqfuRtP48LDLF4L2cAm1S1WFV9wGzgRGLzXkK1lP6YzBNE5FpgBnClNg4CO+R76SqB4BNghIgMEZEUXMPKKx2cpoiJiODqoVep6m9DDr0CXOu9vxZ4ub3T1laqeq+qFqjqYNzf4W1VvYrYvJedQKGIjPJ2fQVYSQzeC65K6AQRyfD+vX0F1xYVi/cSqqX0vwJcJiKpIjIEGAF83AHpi5iITAPuBs5X1eqQQ4d+L6raJX6Ac3At7RuA+zo6PW1M+0m4ot7nwDLv5xwgD9cTYp332qOj09rG+5oKvOq9j8l7AcYDi72/zUtA9xi+lx8Cq4HlwD+B1Fi6F+BpXPuGD/eUfGNr6Qfu8/KDNcD0jk5/BPeyHtcW0JAHPHy47sWmmDDGmC6uq1QNGWOMaYEFAmOM6eIsEBhjTBdngcAYY7o4CwTGGNPFWSAwph2JyNSGGVeN6SwsEBhjTBdngcCYMETkKhH5WESWichfvPUTKkXkNyKyVETeEpGe3rnjRWRRyDzx3b39w0XkTRH5zLtmmPfxWSFrGDzljeQ1psNYIDCmGREZA3wdmKKq44EAcCWQCSxV1WOBhcD3vUv+Adytbp74L0L2PwX8SVWPxs3bs8PbfwxwJ25tjKG4+ZeM6TBJHZ0AYzqhrwATgE+8h/V03GRlQeBf3jlPArNFJAfIVdWF3v4ngOdEJBvor6ovAqhqLYD3eR+rapG3vQwYDLwX9bsypgUWCIzZnwBPqOq9TXaKPNDsvNbmZ2mtuqcu5H0A+39oOphVDRmzv7eAr4lIL/hy3dtBuP8vX/POuQJ4T1XLgH0icrK3/2pgobr1IopE5ELvM1JFJKM9b8KYSNmTiDHNqOpKEbkfmCsiCbgZIG/FLTxzhIgsAcpw7Qjgpjd+2MvoNwLXe/uvBv4iIj/yPuOSdrwNYyJms48aEyERqVTVrI5OhzGHm1UNGWNMF2clAmOM6eKsRGCMMV2cBQJjjOniLBAYY0wXZ4HAGGO6OAsExhjTxf1/BKxY2QNzQTsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('accuracy.png', dpi=180, facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9999987\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.9999999\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = \"Sandra grabbed Mary in the kitchen . Sandra picked the apple in the garden . John got back in the office . Mary got the milk . Daniel discarded the apple .\"\n",
    "my_question = \"Is apple in the garden ?\"\n",
    "mydata = [(my_story.split(),my_question.split(),'yes')]\n",
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.999642\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = 'Daniel grabbed the apple there . Daniel went to the bedroom . John moved to the garden . Sandra journeyed to the office . Daniel put down the apple . Mary went to the bedroom . Mary grabbed the apple there . Sandra went back to the garden . Mary went to the kitchen . Daniel went to the office .'\n",
    "my_question = \"Is Mary in the kitchen ?\"\n",
    "mydata = [(my_story.split(),my_question.split(),'yes')]\n",
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.99999845\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = 'Daniel grabbed the apple there . Daniel went to the bedroom . John moved to the garden . Sandra journeyed to the office . Daniel put down the apple . Mary went to the bedroom . Mary grabbed the apple there . Sandra went back to the garden . Mary went to the kitchen . Daniel went to the office .'\n",
    "my_question = \"Is Mary in the bedroom ?\"\n",
    "mydata = [(my_story.split(),my_question.split(),'no')]\n",
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.99998736\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
